{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Digit Classification - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "from theano.tensor.signal import pool\n",
    "from theano.tensor.nnet import conv2d\n",
    "\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../../data\"\n",
    "TRAIN_FILE = os.path.join(DATA_DIR, \"mnist_train.csv\")\n",
    "TEST_FILE = os.path.join(DATA_DIR, \"mnist_test.csv\")\n",
    "\n",
    "MODEL_FILE = os.path.join(DATA_DIR, \"theano-mnist-cnn\")\n",
    "\n",
    "LEARNING_RATE = 0.001\n",
    "REG_LAMBDA = 0.01\n",
    "\n",
    "INPUT_SIZE = 28\n",
    "BATCH_SIZE = 128\n",
    "NUM_CLASSES = 10\n",
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist_train.csv: 0 lines read\n",
      "mnist_train.csv: 10000 lines read\n",
      "mnist_train.csv: 20000 lines read\n",
      "mnist_train.csv: 30000 lines read\n",
      "mnist_train.csv: 40000 lines read\n",
      "mnist_train.csv: 50000 lines read\n",
      "mnist_train.csv: 60000 lines read\n",
      "mnist_test.csv: 0 lines read\n",
      "mnist_test.csv: 10000 lines read\n",
      "(60000, 1, 28, 28) (60000,) (10000, 1, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def parse_file(filename):\n",
    "    xdata, ydata = [], []\n",
    "    fin = open(filename, \"rb\")\n",
    "    i = 0\n",
    "    for line in fin:\n",
    "        if i % 10000 == 0:\n",
    "            print(\"{:s}: {:d} lines read\".format(\n",
    "                os.path.basename(filename), i))\n",
    "        cols = line.strip().split(\",\")\n",
    "        ydata.append(int(cols[0]))\n",
    "        x1d = np.array([float(x) / 255. for x in cols[1:]])\n",
    "#         x1d = np.array([float(x) for x in cols[1:]])\n",
    "        x3d = np.reshape(x1d, (1, INPUT_SIZE, INPUT_SIZE))\n",
    "        xdata.append(x3d)\n",
    "        i += 1\n",
    "    fin.close()\n",
    "    print(\"{:s}: {:d} lines read\".format(os.path.basename(filename), i))\n",
    "    X = np.array(xdata).astype(\"float32\")\n",
    "    y = np.array(ydata).astype(\"int32\")\n",
    "    return X, y\n",
    "\n",
    "Xtrain, ytrain = parse_file(TRAIN_FILE)\n",
    "Xtest, ytest = parse_file(TEST_FILE)\n",
    "print(Xtrain.shape, ytrain.shape, Xtest.shape, ytest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = T.ftensor4(\"X\")\n",
    "y = T.ivector(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CONV1: 5x5 kernel, channels: 1 => 32\n",
    "# filtering reduces the image size to (28-5+1 , 28-5+1) = (24, 24)\n",
    "# maxpooling reduces this further to (24/2, 24/2) = (12, 12)\n",
    "# output tensor of shape (batch_size, 32, 12, 12)\n",
    "W1 = theano.shared(np.random.randn(32, 1, 5, 5)\n",
    "                   .astype(theano.config.floatX), name=\"W1\")\n",
    "conv_1 = conv2d(input=X, filters=W1, filter_shape=(32, 1, 5, 5),\n",
    "                input_shape=(BATCH_SIZE, 1, INPUT_SIZE, INPUT_SIZE))\n",
    "pool_1 = pool.pool_2d(input=conv_1, ws=(2, 2), ignore_border=True)\n",
    "# relu_1 = T.nnet.relu(pool_1)\n",
    "relu_1 = T.tanh(pool_1)\n",
    "\n",
    "# CONV2: 5x5 kernel, channels: 32 => 64\n",
    "# filtering reduces the image size to (12-5+1, 12-5+1) = (8, 8)\n",
    "# maxpooling reduces this further to (8/2, 8/2) = (4, 4)\n",
    "# output tensor of shape (batch_size, 64, 4, 4)\n",
    "W2 = theano.shared(np.random.randn(64, 32, 5, 5)\n",
    "                   .astype(theano.config.floatX), name=\"W2\")\n",
    "conv_2 = conv2d(input=relu_1, filters=W2, filter_shape=(64, 32, 5, 5),\n",
    "               input_shape=(BATCH_SIZE, 32, 12, 12))\n",
    "pool_2 = pool.pool_2d(input=conv_2, ws=(2, 2), ignore_border=True)\n",
    "# relu_2 = T.nnet.relu(pool_2)\n",
    "relu_2 = T.tanh(pool_2)\n",
    "\n",
    "# output tensor of shape (batch_size, 1024)\n",
    "flat_3 = relu_2.reshape((-1, 1024))\n",
    "\n",
    "# fc1: 1024 => 512\n",
    "W4 = theano.shared(np.random.randn(1024, 512)\n",
    "                   .astype(theano.config.floatX), name=\"W4\")\n",
    "b4 = theano.shared(np.zeros(512).astype(theano.config.floatX), name=\"b4\")\n",
    "fc4 = flat_3.dot(W4) + b4\n",
    "# fc4_relu = T.nnet.relu(fc4)\n",
    "fc4_relu = T.tanh(fc4)\n",
    "\n",
    "# fc2: 512 => 10\n",
    "W5 = theano.shared(np.random.randn(512, 10)\n",
    "                   .astype(theano.config.floatX), name=\"W5\")\n",
    "b5 = theano.shared(np.zeros(10).astype(theano.config.floatX), name=\"b5\")\n",
    "fc5 = fc4_relu.dot(W5) + b5\n",
    "y_hat = T.nnet.softmax(fc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = T.nnet.categorical_crossentropy(y_hat, y).mean()\n",
    "prediction = T.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "forward_prop = theano.function([X], y_hat)\n",
    "calculate_loss = theano.function([X, y], loss)\n",
    "predict = theano.function([X], prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = [W5, b5, W4, b4, W2, W1]\n",
    "grads = T.grad(loss, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates = [\n",
    "    (param_i, param_i - LEARNING_RATE * grad_i)\n",
    "    for param_i, grad_i in zip(params, grads)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gradient_step = theano.function(\n",
    "    [X, y],\n",
    "    updates=updates\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: loss=20.3532, accuracy: 0.2393\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "num_batches = len(Xtrain) // BATCH_SIZE\n",
    "num_val_recs = len(Xtrain) // 10\n",
    "Xval, yval = Xtrain[0:num_val_recs], ytrain[0:num_val_recs]\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    shuffled_indices = np.random.permutation(np.arange(len(Xtrain)))\n",
    "    total_loss, total_acc = 0., 0.\n",
    "    for bid in range(num_batches - 1):\n",
    "        bstart = bid * BATCH_SIZE\n",
    "        bend = (bid + 1) * BATCH_SIZE\n",
    "        Xbatch = np.array([Xtrain[i] for i in shuffled_indices[bstart:bend]])\n",
    "        ybatch = np.array([ytrain[i] for i in shuffled_indices[bstart:bend]])\n",
    "        gradient_step(Xbatch, ybatch)\n",
    "        total_loss += calculate_loss(Xbatch, ybatch)\n",
    "    total_loss /= num_batches\n",
    "    # validate with 10% training data\n",
    "    yval_ = predict(Xval)\n",
    "    total_acc = accuracy_score(yval_, yval)\n",
    "    history.append((total_loss, total_acc))\n",
    "    print(\"Epoch {:d}/{:d}: loss={:.4f}, accuracy: {:.4f}\".format(\n",
    "        epoch+1, NUM_EPOCHS, total_loss, total_acc))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "losses = [x[0] for x in history]\n",
    "accs = [x[1] for x in history]\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.plot(accs)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(losses)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict_fn = theano.function([X], prediction)\n",
    "ytest_ = predict_fn(Xtest)\n",
    "acc = accuracy_score(ytest_, ytest)\n",
    "cm = confusion_matrix(ytest_, ytest)\n",
    "print(\"accuracy: {:.3f}\".format(acc))\n",
    "print(\"confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
